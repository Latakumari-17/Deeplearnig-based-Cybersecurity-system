{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d71d5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3020264855491919\n",
      "Epoch 2, Loss: 0.027925693454700664\n",
      "Epoch 3, Loss: 0.0169426445846888\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import functional as sf\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load and transform malware image dataset (replace with your dataset path)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(), \n",
    "    transforms.Resize((28, 28)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Example: Load MNIST as a placeholder dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='C:\\\\Users\\\\DELL\\\\Documents\\\\hackathon\\\\train', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='C:\\\\Users\\\\DELL\\\\Documents\\\\hackathon\\\\test', train=False, download=True, transform=transform)\n",
    "\n",
    "binary_indices_test = [i for i, (img, label) in enumerate(test_dataset) if label in [0, 1]]\n",
    "test_dataset_binary = Subset(test_dataset, binary_indices_test)\n",
    "\n",
    "binary_indices = [i for i, (img, label) in enumerate(train_dataset) if label in [0, 1]]\n",
    "train_dataset_binary = Subset(train_dataset, binary_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset_binary, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_binary, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define SNN Model\n",
    "class SNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.lif1 = snn.Leaky(beta=0.9)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        self.lif2 = snn.Leaky(beta=0.9)\n",
    "\n",
    "    def forward(self, x, num_steps=25):\n",
    "        mem1, mem2 = self.lif1.init_leaky(), self.lif2.init_leaky()\n",
    "        x = x.view(x.size(0), -1)\n",
    "        spk2_rec = []\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            spk1, mem1 = self.lif1(self.fc1(x), mem1)\n",
    "            spk2, mem2 = self.lif2(self.fc2(spk1), mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "\n",
    "        return torch.stack(spk2_rec)\n",
    "\n",
    "# Train the Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SNNModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = sf.mse_count_loss()\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for data, targets in train_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        targets_oh = torch.nn.functional.one_hot(targets, num_classes=2).float()\n",
    "\n",
    "        spk_rec = model(data)\n",
    "        loss = loss_fn(spk_rec, targets)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "# Save Model\n",
    "torch.save(model.state_dict(), \"malware_snn1.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7dc16b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "Train Loss: 0.0043 | Train Acc: 99.95%\n",
      "Test Loss:   0.0110 | Test Acc:   99.95%\n",
      "\n",
      "Epoch [2/10]\n",
      "Train Loss: 0.0136 | Train Acc: 99.87%\n",
      "Test Loss:   0.0142 | Test Acc:   99.91%\n",
      "\n",
      "Epoch [3/10]\n",
      "Train Loss: 0.0086 | Train Acc: 99.91%\n",
      "Test Loss:   0.0156 | Test Acc:   99.91%\n",
      "\n",
      "Epoch [4/10]\n",
      "Train Loss: 0.0028 | Train Acc: 99.98%\n",
      "Test Loss:   0.0104 | Test Acc:   99.91%\n",
      "\n",
      "Epoch [5/10]\n",
      "Train Loss: 0.0023 | Train Acc: 99.97%\n",
      "Test Loss:   0.0089 | Test Acc:   99.95%\n",
      "\n",
      "Epoch [6/10]\n",
      "Train Loss: 0.0006 | Train Acc: 99.99%\n",
      "Test Loss:   0.0093 | Test Acc:   99.95%\n",
      "\n",
      "Epoch [7/10]\n",
      "Train Loss: 0.0011 | Train Acc: 99.97%\n",
      "Test Loss:   0.0031 | Test Acc:   99.91%\n",
      "\n",
      "Epoch [8/10]\n",
      "Train Loss: 0.0004 | Train Acc: 99.98%\n",
      "Test Loss:   0.0057 | Test Acc:   99.86%\n",
      "\n",
      "Epoch [9/10]\n",
      "Train Loss: 0.0001 | Train Acc: 99.99%\n",
      "Test Loss:   0.0045 | Test Acc:   99.86%\n",
      "\n",
      "Epoch [10/10]\n",
      "Train Loss: 0.0001 | Train Acc: 99.99%\n",
      "Test Loss:   0.0050 | Test Acc:   99.86%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, targets in train_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        spk_rec = model(data)  # Shape: [time, batch, output]\n",
    "        \n",
    "        # Sum across time\n",
    "        out_spikes = spk_rec.sum(dim=0)  # Shape: [batch, output]\n",
    "        loss = criterion(out_spikes, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = out_spikes.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100. * correct / total\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "            spk_rec = model(data)\n",
    "            out_spikes = spk_rec.sum(dim=0)\n",
    "            loss = criterion(out_spikes, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = out_spikes.max(1)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "    test_loss = test_loss / len(val_loader)\n",
    "    test_acc = 100. * correct / total\n",
    "    return test_loss, test_acc\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{10}]\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Test Loss:   {test_loss:.4f} | Test Acc:   {test_acc:.2f}%\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
